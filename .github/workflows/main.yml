#  scraping
name: sitemap_scraping

# Controls when the action will run.
on:
  push:
    branches: main

jobs: 
  autoscrape:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Load repo and install R
    steps:
    - uses: actions/checkout@v2
    - uses: r-lib/actions/setup-r@v2  # Use a specific release or tag here
      with:
        r-version: 4.1

    # Set-up R
    - name: Install packages
      run: |
        R -e 'install.packages("rvest")'
        R -e 'install.packages("data.table")'
        R -e 'install.packages("dplyr")'
        R -e 'install.packages("tidyr")'
        R -e 'install.packages("renv")'
      
    - name: Display R library paths
      run: R -e 'library()'

    - uses: actions/cache@v2 # Cache packages so won't be compiled everytime job is run
      with:
        path: ~/.local/share/renv
        key: ${{ runner.os }}-renv-${{ hashFiles('**/renv.lock') }}
        restore-keys: |
          ${{ runner.os }}-renv-

    - name: Install dependencies # Install the dependencies eg. Dplyr, tidyverse etc
      run: renv::restore()
      shell: Rscript {0}   
      
    - name: Setup renv
      run: R -e 'renv::init()'
            

    - name: Generate data # Run the script
      run: source("/workspaces/scrape-automation/scraper.r")
      shell: Rscript {0}

    - name: Install dependencies
      run: R -e 'renv::restore()'

    # Run R script
   # - name: Scrape
     # run: R_LIBS_USER=/home/runner/work/_temp/Library Rscript scraper.r
      
 # Add new files in data folder, commit along with other modified files, push
    - name: Commit files
      run: |
        git config --local user.name actions-user
        git config --local user.email "actions@github.com"
        git add data/*
        git commit -am "GH ACTION Headlines $(date)"
        git push origin main
      env:
        REPO_KEY: ${{secrets.GITHUB_TOKEN}}
        username: github-actions